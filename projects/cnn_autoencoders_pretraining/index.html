<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Pretraining of deep CNN autoencoders | Tomáš Čelko </title> <meta name="author" content="Tomáš Čelko"> <meta name="description" content="Autoencoders pretrained on unlabeled data from Timepix3 to improve accuracy."> <meta name="keywords" content="celko cluster clustering"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://tomascelko.github.io/projects/cnn_autoencoders_pretraining/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Tomáš</span> Čelko </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Pretraining of deep CNN autoencoders</h1> <p class="post-description">Autoencoders pretrained on unlabeled data from Timepix3 to improve accuracy.</p> </header> <article> <h2 id="goal">Goal</h2> <p>The goal of the project is to show how pretraining autoencoders based on CNNs can be used to learn feature extraction and subsequently finetune for specific task. This page was made to showcase some of the figures relevant to the project.</p> <h2 id="model">Model</h2> <p>We have chosen the EfficientNetB4 as our model architecture of the encoder. For the decoder, we transpose the architecture of the encoder. Additionally, we attach multiple heads to the model -</p> <ul> <li>First head predicts the image on the input</li> <li>Second head predicts binary mask of the whole cluster</li> <li>Third head predict the binary mask of pixels above fixed threashold</li> </ul> <h3 id="variations">Variations</h3> <ul> <li>Different levels of input pixel masking were tried (0%, 25% and 50%)</li> <li>Variations with or without binary mask head were tested</li> </ul> <h2 id="input">Input</h2> <p>As input to the model we use 3 channel image of size 384x384, which is upsampled image of the cluster (up to 5x size increase in each dimension).</p> <ul> <li>First chanel is dedicated to deposited energy for each pixel.</li> <li>Second channel is for the time of arrival of each pixel</li> <li>Third channel contains binary map of the pixels above certain energy threshold Data is normalized using sqare-root normalization.</li> </ul> <h2 id="training">Training</h2> <h3 id="pretraining">Pretraining</h3> <p>The pretraining has two stages :</p> <ol> <li> <p>Standard pretraining on Imagenet dataset - we simply download the pretrained weights from for this torchvision model.</p> </li> <li> <p>Part of the data for unsupervised pretraining is obtained from Timepix3 measurements in ATLAS. This dataset contains high variability of clusters but smaller clusters are much more frequent. This is the reason why we also used ions data obtained at test beam measurements of Pb at SPS at Cern - these have higher frequency of large clusters.</p> </li> </ol> <p>Dataset is balanced into exponentially sized bins based on cluster hit count. We then downsample the clusters so that the frequency across the bins is unfiorm.</p> <div class="row"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/AE_CNN/curve-480.webp 480w,/assets/AE_CNN/curve-800.webp 800w,/assets/AE_CNN/curve-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/AE_CNN/curve.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Reconstruction of energy of a curly track using CNN autoencoder as a function of number of training iterations" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figcaption class="mt-2 text-muted"> Reconstruction of energy of a curly track using a CNN autoencoder as a function of training iterations. </figcaption> </figure> </div> <div class="row"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/AE_CNN/curve2-480.webp 480w,/assets/AE_CNN/curve2-800.webp 800w,/assets/AE_CNN/curve2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/AE_CNN/curve2.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Reconstruction of energy of a curly track using CNN autoencoder as a function of number of training iterations" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </figure> </div> <div class="row"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/AE_CNN/hblob-480.webp 480w,/assets/AE_CNN/hblob-800.webp 800w,/assets/AE_CNN/hblob-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/AE_CNN/hblob.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Reconstruction of energy of ion track using CNN autoencoder as a function of number of training iterations" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </figure> </div> <div class="row"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/AE_CNN/hion-480.webp 480w,/assets/AE_CNN/hion-800.webp 800w,/assets/AE_CNN/hion-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/AE_CNN/hion.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Reconstruction of energy of ion track using CNN autoencoder as a function of number of training iterations" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </figure> </div> <div class="row"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/AE_CNN/htrack-480.webp 480w,/assets/AE_CNN/htrack-800.webp 800w,/assets/AE_CNN/htrack-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/AE_CNN/htrack.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Reconstruction of ion track using CNN autoencoder as a function of number of training iterations" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </figure> </div> <h4 id="what-happens-if-we-do-not-use-binary-pixel-masking">What happens, if we do not use binary pixel masking?</h4> <p>Suddenly, the thin tracks become more blurry as we can see below.</p> <div class="row"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/AE_CNN/curve_no_mask-480.webp 480w,/assets/AE_CNN/curve_no_mask-800.webp 800w,/assets/AE_CNN/curve_no_mask-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/AE_CNN/curve_no_mask.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Reconstruction of electron track using CNN autoencoder as a function of number of training iterations. This time, no binary mask predicition is used" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </figure> </div> <div class="row"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/AE_CNN/htrack_no_mask-480.webp 480w,/assets/AE_CNN/htrack_no_mask-800.webp 800w,/assets/AE_CNN/htrack_no_mask-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/AE_CNN/htrack_no_mask.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Reconstruction of ion track using CNN autoencoder as a function of number of training iterations. This time, no binary mask predicition mask is used" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </figure> </div> <h4 id="key-observations">Key observations:</h4> <ul> <li>addition of binary mask predicition non-trivially increased the sharpness of the recontructed image</li> <li>we were able to reconstruct simple, linear tracks with high precision</li> <li>heavy ions were reconstructed too but reconstructing areas with high density of delta electrons ended up blurred</li> </ul> <h3 id="supervised-finetuning">Supervised finetuning</h3> <p>Data for supervised finetuning is obtained from simulations. For instance, we simulate protons and electrons for SATRAM experiment with Timepix1. Currently, there is a lack of standardized benchmarking datasets for this type of detectors, so besides simulation of real spectrum for SATRAM instrument, we also created identical spectrum to the one mentioned in this paper <a href="https://hal.science/hal-03238974v1/document" rel="external nofollow noopener" target="_blank"> </a>, further referred to as “reference spectrum” as opposed to the original “real spectrum”.</p> <div class="row"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/AE_CNN/electron_real_spectrum" sizes="95vw"></source> <img src="/assets/AE_CNN/electron_real_spectrum" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Simulated real SATRAM electron spectrum" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </figure> </div> <div class="row"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/AE_CNN/proton_real_spectrum" sizes="95vw"></source> <img src="/assets/AE_CNN/proton_real_spectrum" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Simulated real SATRAM proton spectrum" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </figure> </div> <h4 id="validation">Validation</h4> <p>TBD, add plots</p> <h4 id="separated-protons-and-electron-feature-vectors">Separated protons and electron feature vectors</h4> <div class="row"> <figure class="text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/AE_CNN/umap_mask0_after-480.webp 480w,/assets/AE_CNN/umap_mask0_after-800.webp 800w,/assets/AE_CNN/umap_mask0_after-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/AE_CNN/umap_mask0_after.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Projection of extracted features of each cluster to 2D using UMAP" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <figcaption class="mt-2 text-muted"> Projection of feature vector obtained from CNN encoder into 2D AFTER unsupervised pretraining on ATLAS data and also AFTER supervised finetuning to split protons from electrons. Some tracks were selected (using K-means) and for these we also show energy deposition and the tracks shape in a square box. We can see that tracks with similar angle are close together indicating model learned the feature to recognize particle angle. Another extracted feature seems to be track length. This is indeed building meaningful and interpretable features, not just copying data to the output. </figcaption> </figure> </div> <h4 id="key-observations-1">Key observations</h4> <ul> <li>two of the most important extracted features by the model were track length and angle of the track</li> <li>by using the pretrained model, we were able to improve the separation of protons and electrons on reference spectrum from reported 94.79% to our 96.2%</li> <li>we have shown that most of the errors are caused by lack of information (tracks smaller than 8 pixels), after filtering those we achieved &gt;99% accuracy on a balanced dataset</li> </ul> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Tomáš Čelko. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: April 30, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"A few projects which I implemented - varying from smaller to larger ones.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"cv",description:"This is a description of the page. You can modify it in &#39;_pages/cv.md&#39;. You can also change or remove the top pdf download button.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-teaching",title:"teaching",description:"A short history of the courses I taught.",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"projects-audio-visualizer",title:"audio_visualizer",description:"A tool to play .wav tracks and visualize fast fourier transform decomposition of the played tune.",section:"Projects",handler:()=>{window.location.href="/projects/audio_visualizer/"}},{id:"projects-chess",title:"Chess",description:"Chess with a simple GUI, and AI oponent based on minimax with alpha-beta prunning algorithm",section:"Projects",handler:()=>{window.location.href="/projects/chess_game/"}},{id:"projects-clusterer-lite",title:"clusterer_lite",description:"Liteweight implementation of clustering targeted at on-chip data processing.",section:"Projects",handler:()=>{window.location.href="/projects/clusterer_lite/"}},{id:"projects-pretraining-of-deep-cnn-autoencoders",title:"Pretraining of deep CNN autoencoders",description:"Autoencoders pretrained on unlabeled data from Timepix3 to improve accuracy.",section:"Projects",handler:()=>{window.location.href="/projects/cnn_autoencoders_pretraining/"}},{id:"projects-comparison-of-dimensionality-reduction-techniques",title:"Comparison of dimensionality reduction techniques",description:"Application of pretrained NN combined with dimensionality reduction for visualization and classification of image data.",section:"Projects",handler:()=>{window.location.href="/projects/dimensionality_reduction/"}},{id:"projects-neat-coevolution",title:"Neat-coevolution",description:"Evolving neural networks using NEAT in co-evolution environment",section:"Projects",handler:()=>{window.location.href="/projects/neat_coevolution/"}},{id:"projects-parallel-clustering-library",title:"Parallel clustering library",description:"Fast connected component analysis for hybrid pixel detectors",section:"Projects",handler:()=>{window.location.href="/projects/parallel_clustering/"}},{id:"projects-pixel-auto",title:"pixel_auto",description:"Development of methodology for application of finite automatons to particle classification",section:"Projects",handler:()=>{window.location.href="/projects/pixel_auto/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%6F%75@%65%78%61%6D%70%6C%65.%63%6F%6D","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0009-0003-3077-3223","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>